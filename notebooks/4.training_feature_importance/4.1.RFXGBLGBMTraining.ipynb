{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84e1bb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f911342d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precio</th>\n",
       "      <th>banos</th>\n",
       "      <th>dormitorios</th>\n",
       "      <th>superficie_total</th>\n",
       "      <th>superficie_construida</th>\n",
       "      <th>estacionamiento</th>\n",
       "      <th>latitud</th>\n",
       "      <th>longitud</th>\n",
       "      <th>comuna</th>\n",
       "      <th>poblaci√≥n 2024</th>\n",
       "      <th>...</th>\n",
       "      <th>pct_cocina_moderna</th>\n",
       "      <th>pct_propia_total</th>\n",
       "      <th>pct_arrendada</th>\n",
       "      <th>ingreso_promedio</th>\n",
       "      <th>ingreso_mediana</th>\n",
       "      <th>indice_calidad_materiales</th>\n",
       "      <th>indice_servicios_basicos</th>\n",
       "      <th>indice_calidad_vivienda_general</th>\n",
       "      <th>distancia_hospital</th>\n",
       "      <th>distancia_metro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>322633576.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>404.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-33.345468</td>\n",
       "      <td>-70.678398</td>\n",
       "      <td>huechuraba</td>\n",
       "      <td>101808.0</td>\n",
       "      <td>...</td>\n",
       "      <td>89.86</td>\n",
       "      <td>64.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>720051.66</td>\n",
       "      <td>402500.0</td>\n",
       "      <td>86.47</td>\n",
       "      <td>61.35</td>\n",
       "      <td>74.64</td>\n",
       "      <td>8064.787023</td>\n",
       "      <td>2554.229150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>157180460.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-33.563025</td>\n",
       "      <td>-70.559425</td>\n",
       "      <td>puente alto</td>\n",
       "      <td>568086.0</td>\n",
       "      <td>...</td>\n",
       "      <td>90.62</td>\n",
       "      <td>69.71</td>\n",
       "      <td>0.18</td>\n",
       "      <td>538232.86</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>93.75</td>\n",
       "      <td>65.79</td>\n",
       "      <td>78.18</td>\n",
       "      <td>845.094730</td>\n",
       "      <td>2324.734493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>133544301.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-33.641678</td>\n",
       "      <td>-70.689872</td>\n",
       "      <td>san bernardo</td>\n",
       "      <td>306371.0</td>\n",
       "      <td>...</td>\n",
       "      <td>90.21</td>\n",
       "      <td>58.31</td>\n",
       "      <td>1.16</td>\n",
       "      <td>488733.18</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>89.94</td>\n",
       "      <td>62.44</td>\n",
       "      <td>76.41</td>\n",
       "      <td>5475.616211</td>\n",
       "      <td>11151.846959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>117786861.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-33.613778</td>\n",
       "      <td>-70.887450</td>\n",
       "      <td>pe√±aflor</td>\n",
       "      <td>94402.0</td>\n",
       "      <td>...</td>\n",
       "      <td>89.12</td>\n",
       "      <td>65.85</td>\n",
       "      <td>0.19</td>\n",
       "      <td>591753.35</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>84.18</td>\n",
       "      <td>62.29</td>\n",
       "      <td>77.28</td>\n",
       "      <td>1600.028166</td>\n",
       "      <td>16662.321199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>153241100.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-33.360659</td>\n",
       "      <td>-70.709209</td>\n",
       "      <td>quilicura</td>\n",
       "      <td>205624.0</td>\n",
       "      <td>...</td>\n",
       "      <td>93.53</td>\n",
       "      <td>61.08</td>\n",
       "      <td>0.38</td>\n",
       "      <td>549642.87</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>94.77</td>\n",
       "      <td>67.11</td>\n",
       "      <td>74.76</td>\n",
       "      <td>7622.326772</td>\n",
       "      <td>1948.472205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4503</th>\n",
       "      <td>234059250.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-33.488703</td>\n",
       "      <td>-70.744430</td>\n",
       "      <td>maip√∫</td>\n",
       "      <td>503635.0</td>\n",
       "      <td>...</td>\n",
       "      <td>92.76</td>\n",
       "      <td>70.40</td>\n",
       "      <td>0.80</td>\n",
       "      <td>601743.03</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>94.91</td>\n",
       "      <td>69.46</td>\n",
       "      <td>78.23</td>\n",
       "      <td>3514.318855</td>\n",
       "      <td>711.188857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4504</th>\n",
       "      <td>95000000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-33.499393</td>\n",
       "      <td>-70.776072</td>\n",
       "      <td>maip√∫</td>\n",
       "      <td>503635.0</td>\n",
       "      <td>...</td>\n",
       "      <td>92.76</td>\n",
       "      <td>70.40</td>\n",
       "      <td>0.80</td>\n",
       "      <td>601743.03</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>94.91</td>\n",
       "      <td>69.46</td>\n",
       "      <td>78.23</td>\n",
       "      <td>995.045138</td>\n",
       "      <td>1765.069675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4505</th>\n",
       "      <td>742425000.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>370.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-33.421135</td>\n",
       "      <td>-70.553193</td>\n",
       "      <td>las condes</td>\n",
       "      <td>296134.0</td>\n",
       "      <td>...</td>\n",
       "      <td>98.33</td>\n",
       "      <td>56.67</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1806493.23</td>\n",
       "      <td>1050000.0</td>\n",
       "      <td>97.94</td>\n",
       "      <td>92.51</td>\n",
       "      <td>77.68</td>\n",
       "      <td>4638.577959</td>\n",
       "      <td>1526.624955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4506</th>\n",
       "      <td>69709800.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-33.513907</td>\n",
       "      <td>-70.783665</td>\n",
       "      <td>maip√∫</td>\n",
       "      <td>503635.0</td>\n",
       "      <td>...</td>\n",
       "      <td>92.76</td>\n",
       "      <td>70.40</td>\n",
       "      <td>0.80</td>\n",
       "      <td>601743.03</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>94.91</td>\n",
       "      <td>69.46</td>\n",
       "      <td>78.23</td>\n",
       "      <td>1078.534716</td>\n",
       "      <td>2485.915755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4507</th>\n",
       "      <td>75000000.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-33.416357</td>\n",
       "      <td>-70.765798</td>\n",
       "      <td>cerro navia</td>\n",
       "      <td>127250.0</td>\n",
       "      <td>...</td>\n",
       "      <td>94.41</td>\n",
       "      <td>61.98</td>\n",
       "      <td>1.98</td>\n",
       "      <td>446483.01</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>88.17</td>\n",
       "      <td>58.32</td>\n",
       "      <td>70.63</td>\n",
       "      <td>2381.181842</td>\n",
       "      <td>3924.559734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4508 rows √ó 163 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           precio  banos  dormitorios  superficie_total  \\\n",
       "0     322633576.0    3.0          5.0             404.0   \n",
       "1     157180460.0    2.0          3.0             190.0   \n",
       "2     133544301.0    2.0          5.0             146.0   \n",
       "3     117786861.0    2.0          3.0             145.0   \n",
       "4     153241100.0    4.0          4.0             172.0   \n",
       "...           ...    ...          ...               ...   \n",
       "4503  234059250.0    3.0          5.0             140.0   \n",
       "4504   95000000.0    2.0          6.0             110.0   \n",
       "4505  742425000.0    5.0          5.0             370.0   \n",
       "4506   69709800.0    1.0          2.0              88.0   \n",
       "4507   75000000.0    2.0          4.0             100.0   \n",
       "\n",
       "      superficie_construida  estacionamiento    latitud   longitud  \\\n",
       "0                     275.0              1.0 -33.345468 -70.678398   \n",
       "1                     127.0              1.0 -33.563025 -70.559425   \n",
       "2                      61.0              1.0 -33.641678 -70.689872   \n",
       "3                      82.0              1.0 -33.613778 -70.887450   \n",
       "4                      82.0              1.0 -33.360659 -70.709209   \n",
       "...                     ...              ...        ...        ...   \n",
       "4503                  101.0              0.0 -33.488703 -70.744430   \n",
       "4504                   95.0              0.0 -33.499393 -70.776072   \n",
       "4505                  230.0              0.0 -33.421135 -70.553193   \n",
       "4506                   70.0              0.0 -33.513907 -70.783665   \n",
       "4507                   80.0              0.0 -33.416357 -70.765798   \n",
       "\n",
       "            comuna  poblaci√≥n 2024  ...  pct_cocina_moderna  pct_propia_total  \\\n",
       "0       huechuraba        101808.0  ...               89.86             64.31   \n",
       "1      puente alto        568086.0  ...               90.62             69.71   \n",
       "2     san bernardo        306371.0  ...               90.21             58.31   \n",
       "3         pe√±aflor         94402.0  ...               89.12             65.85   \n",
       "4        quilicura        205624.0  ...               93.53             61.08   \n",
       "...            ...             ...  ...                 ...               ...   \n",
       "4503         maip√∫        503635.0  ...               92.76             70.40   \n",
       "4504         maip√∫        503635.0  ...               92.76             70.40   \n",
       "4505    las condes        296134.0  ...               98.33             56.67   \n",
       "4506         maip√∫        503635.0  ...               92.76             70.40   \n",
       "4507   cerro navia        127250.0  ...               94.41             61.98   \n",
       "\n",
       "      pct_arrendada  ingreso_promedio  ingreso_mediana  \\\n",
       "0              0.00         720051.66         402500.0   \n",
       "1              0.18         538232.86         400000.0   \n",
       "2              1.16         488733.18         400000.0   \n",
       "3              0.19         591753.35         400000.0   \n",
       "4              0.38         549642.87         450000.0   \n",
       "...             ...               ...              ...   \n",
       "4503           0.80         601743.03         450000.0   \n",
       "4504           0.80         601743.03         450000.0   \n",
       "4505           0.49        1806493.23        1050000.0   \n",
       "4506           0.80         601743.03         450000.0   \n",
       "4507           1.98         446483.01         400000.0   \n",
       "\n",
       "      indice_calidad_materiales  indice_servicios_basicos  \\\n",
       "0                         86.47                     61.35   \n",
       "1                         93.75                     65.79   \n",
       "2                         89.94                     62.44   \n",
       "3                         84.18                     62.29   \n",
       "4                         94.77                     67.11   \n",
       "...                         ...                       ...   \n",
       "4503                      94.91                     69.46   \n",
       "4504                      94.91                     69.46   \n",
       "4505                      97.94                     92.51   \n",
       "4506                      94.91                     69.46   \n",
       "4507                      88.17                     58.32   \n",
       "\n",
       "      indice_calidad_vivienda_general  distancia_hospital  distancia_metro  \n",
       "0                               74.64         8064.787023      2554.229150  \n",
       "1                               78.18          845.094730      2324.734493  \n",
       "2                               76.41         5475.616211     11151.846959  \n",
       "3                               77.28         1600.028166     16662.321199  \n",
       "4                               74.76         7622.326772      1948.472205  \n",
       "...                               ...                 ...              ...  \n",
       "4503                            78.23         3514.318855       711.188857  \n",
       "4504                            78.23          995.045138      1765.069675  \n",
       "4505                            77.68         4638.577959      1526.624955  \n",
       "4506                            78.23         1078.534716      2485.915755  \n",
       "4507                            70.63         2381.181842      3924.559734  \n",
       "\n",
       "[4508 rows x 163 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/processed/data_final.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68735225",
   "metadata": {},
   "source": [
    "Para poder trabajar correctamente con la columna de 'comuna' se requiere usar herramientas de encoding, esto debido a que random forest, xgboost y lgbm no pueden trabajar con strings(palabras), por lo que se requiere que se transformen a n√∫meros, hay varios tipos de encoding, one-hot encoding, label encoding, o embedding, el que voy a usar es el label-encoding, el cual le asigna una secuencia de n√∫meros a las categor√≠as √∫nicas de la variable, por ejemplo Alhu√© es 1 Buin 2 y as√≠ sucesivamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d063aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['comuna'] = le.fit_transform(df['comuna'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63c9f40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "import numpy as np\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b519f527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tama√±o conjunto entrenamiento: (3606, 162)\n",
      "Tama√±o conjunto prueba: (902, 162)\n"
     ]
    }
   ],
   "source": [
    "y = df['precio']\n",
    "X = df.drop(columns=['precio'])\n",
    "\n",
    "y_binned = pd.qcut(y, q=10, duplicates='drop')\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y_binned\n",
    ")\n",
    "\n",
    "print(f\"Tama√±o conjunto entrenamiento: {X_train.shape}\")\n",
    "print(f\"Tama√±o conjunto prueba: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d80601cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = Pipeline([\n",
    "    ('scaler', RobustScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aed3f5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred):\n",
    "    \"\"\"Calcula todas las m√©tricas requeridas\"\"\"\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    mae_percentage = (mae / y_true.mean()) * 100\n",
    "    \n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    \n",
    "    return {\n",
    "        'MAE': mae,\n",
    "        'MAE_%': mae_percentage,\n",
    "        'RMSE': rmse,\n",
    "        'R¬≤': r2,\n",
    "        'MAPE': mape\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "629f3bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_log_corrected(pipeline, X, y, cv=5):\n",
    "    kf = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "    mae_scores = []\n",
    "    r2_scores = []\n",
    "    \n",
    "    for train_idx, val_idx in kf.split(X):\n",
    "        X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        y_train_log_fold = np.log1p(y_train_fold)\n",
    "        pipeline.fit(X_train_fold, y_train_log_fold)\n",
    "        \n",
    "        y_pred_log_fold = pipeline.predict(X_val_fold)\n",
    "        y_pred_original_fold = np.expm1(y_pred_log_fold)\n",
    "        \n",
    "        mae_scores.append(mean_absolute_error(y_val_fold, y_pred_original_fold))\n",
    "        r2_scores.append(r2_score(y_val_fold, y_pred_original_fold))\n",
    "    \n",
    "    return np.array(mae_scores), np.array(r2_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3e97e398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST\n",
      "MAE: 38915937.525\n",
      "MAE_%: 17.220\n",
      "RMSE: 61689030.250\n",
      "R¬≤: 0.865\n",
      "MAPE: 20.722\n"
     ]
    }
   ],
   "source": [
    "print(\"RANDOM FOREST\")\n",
    "\n",
    "rf_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=5,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "y_pred_rf = rf_pipeline.predict(X_test)\n",
    "metrics_rf = calculate_metrics(y_test, y_pred_rf)\n",
    "\n",
    "for metric, value in metrics_rf.items():\n",
    "    print(f\"{metric}: {value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "054f7093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBOOST\n",
      "MAE: 39338954.545\n",
      "MAE_%: 17.407\n",
      "RMSE: 61237493.648\n",
      "R¬≤: 0.867\n",
      "MAPE: 20.653\n"
     ]
    }
   ],
   "source": [
    "print(\"XGBOOST\")\n",
    "\n",
    "xgb_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', xgb.XGBRegressor(\n",
    "        n_estimators=150,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=4,\n",
    "        reg_alpha=0.1,\n",
    "        reg_lambda=1.0,\n",
    "        random_state=42,\n",
    "        verbosity=0\n",
    "    ))\n",
    "])\n",
    "\n",
    "xgb_pipeline.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_pipeline.predict(X_test)\n",
    "metrics_xgb = calculate_metrics(y_test, y_pred_xgb)\n",
    "\n",
    "for metric, value in metrics_xgb.items():\n",
    "    print(f\"{metric}: {value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aed8d634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "LIGHTGBM\n",
      "========================================\n",
      "MAE: 40005625.086\n",
      "MAE_%: 17.702\n",
      "RMSE: 61798139.771\n",
      "R¬≤: 0.865\n",
      "MAPE: 20.947\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['LIGHTGBM_VERBOSE'] = '0' \n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"LIGHTGBM\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "lgbm_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', lgb.LGBMRegressor(\n",
    "        n_estimators=150,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=4,\n",
    "        random_state=42,\n",
    "        verbose=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "lgbm_pipeline.fit(X_train, y_train)\n",
    "y_pred_lgbm = lgbm_pipeline.predict(X_test)\n",
    "metrics_lgbm = calculate_metrics(y_test, y_pred_lgbm)\n",
    "\n",
    "for metric, value in metrics_lgbm.items():\n",
    "    print(f\"{metric}: {value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "721516da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Modelo          MAE  MAE_%         RMSE    R¬≤   MAPE\n",
      "Random Forest 38915937.525 17.220 61689030.250 0.865 20.722\n",
      "      XGBoost 39338954.545 17.407 61237493.648 0.867 20.653\n",
      "     LightGBM 40005625.086 17.702 61798139.771 0.865 20.947\n",
      "\n",
      "MEJOR MODELO: Random Forest\n"
     ]
    }
   ],
   "source": [
    "resultados = {\n",
    "    'Modelo': ['Random Forest', 'XGBoost', 'LightGBM'],\n",
    "    'MAE': [metrics_rf['MAE'], metrics_xgb['MAE'], metrics_lgbm['MAE']],\n",
    "    'MAE_%': [metrics_rf['MAE_%'], metrics_xgb['MAE_%'], metrics_lgbm['MAE_%']],\n",
    "    'RMSE': [metrics_rf['RMSE'], metrics_xgb['RMSE'], metrics_lgbm['RMSE']],\n",
    "    'R¬≤': [metrics_rf['R¬≤'], metrics_xgb['R¬≤'], metrics_lgbm['R¬≤']],\n",
    "    'MAPE': [metrics_rf['MAPE'], metrics_xgb['MAPE'], metrics_lgbm['MAPE']]\n",
    "}\n",
    "\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "df_resultados = df_resultados.sort_values('MAE')\n",
    "\n",
    "print(df_resultados.to_string(index=False, float_format='%.3f'))\n",
    "\n",
    "mejor_modelo_final = df_resultados.iloc[0]['Modelo']\n",
    "print(f\"\\nMEJOR MODELO: {mejor_modelo_final}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c36315fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDACI√ìN CRUZADA - AN√ÅLISIS R¬≤ (K=5)\n",
      "Resultados de Validaci√≥n Cruzada (R¬≤):\n",
      "Random Forest:\n",
      "  R¬≤ promedio: 0.8590\n",
      "  R¬≤ desviaci√≥n est√°ndar: 0.0114\n",
      "  R¬≤ por fold: ['0.8566', '0.8395', '0.8655', '0.8594', '0.8738']\n",
      "\n",
      "XGBoost:\n",
      "  R¬≤ promedio: 0.8598\n",
      "  R¬≤ desviaci√≥n est√°ndar: 0.0116\n",
      "  R¬≤ por fold: ['0.8660', '0.8384', '0.8665', '0.8572', '0.8710']\n",
      "\n",
      "LightGBM:\n",
      "  R¬≤ promedio: 0.8622\n",
      "  R¬≤ desviaci√≥n est√°ndar: 0.0129\n",
      "  R¬≤ por fold: ['0.8646', '0.8411', '0.8761', '0.8554', '0.8739']\n",
      "\n",
      "üèÜ MEJOR MODELO EN CV: LightGBM (R¬≤ = 0.8622)\n"
     ]
    }
   ],
   "source": [
    "print(\"VALIDACI√ìN CRUZADA - AN√ÅLISIS R¬≤ (K=5)\")\n",
    "\n",
    "pipelines_cv = {\n",
    "    'Random Forest': rf_pipeline,\n",
    "    'XGBoost': xgb_pipeline,\n",
    "    'LightGBM': lgbm_pipeline\n",
    "}\n",
    "\n",
    "cv_results = {}\n",
    "\n",
    "for name, pipeline in pipelines_cv.items():\n",
    "    cv_r2 = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='r2')\n",
    "    \n",
    "    cv_results[name] = {\n",
    "        'CV_R¬≤_mean': cv_r2.mean(),\n",
    "        'CV_R¬≤_std': cv_r2.std(),\n",
    "        'CV_R¬≤_scores': cv_r2\n",
    "    }\n",
    "\n",
    "print(\"Resultados de Validaci√≥n Cruzada (R¬≤):\")\n",
    "for modelo, resultados in cv_results.items():\n",
    "    print(f\"{modelo}:\")\n",
    "    print(f\"  R¬≤ promedio: {resultados['CV_R¬≤_mean']:.4f}\")\n",
    "    print(f\"  R¬≤ desviaci√≥n est√°ndar: {resultados['CV_R¬≤_std']:.4f}\")\n",
    "    print(f\"  R¬≤ por fold: {[f'{score:.4f}' for score in resultados['CV_R¬≤_scores']]}\") \n",
    "    print()\n",
    "\n",
    "mejor_cv_modelo = max(cv_results.items(), key=lambda x: x[1]['CV_R¬≤_mean'])\n",
    "print(f\"üèÜ MEJOR MODELO EN CV: {mejor_cv_modelo[0]} (R¬≤ = {mejor_cv_modelo[1]['CV_R¬≤_mean']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a383ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['precio', 'banos', 'dormitorios', 'superficie_total', 'superficie_construida', 'estacionamiento', 'latitud', 'longitud', 'comuna', 'poblaci√≥n 2024', '√≠ndice masculinidad 2024', 'grupo_etario_0_a_14_2024_(%)', 'grupo_etario_15_a_29_2024_(%)', 'grupo_etario_30_a_44_2024_(%)', 'grupo_etario_45_a_64_2024_(%)', 'grupo_etario_65_o_mas_2024_(%)', 'idd 2024', 'iam 2024', 'pobreza por ingresos 2022 (%)', 'pobreza multidimensional 2022 (%)', 'pueblos ind√≠genas 2025 (%)', 'extranjeros 2025 (%)', 'carentes servicios b√°sicos 2025 (%)', 'hogares hacinados 2025 (%)', 'cantidad de: atenci√≥n remota 2025', 'cantidad de: centro comunitario de salud familiar (cecosf) 2025', 'cantidad de: centro comunitario de salud mental  (cosam) 2025', 'cantidad de: centro corporaci√≥n para la nutrici√≥n infantil (conin) 2025', 'cantidad de: centro de apoyo comunitario para personas con demencia 2025', 'cantidad de: centro diagn√≥stico terap√©utico y tratamiento privado (cdt) 2025', 'cantidad de: centro de di√°lisis 2025', 'cantidad de: centro de especialidad 2025', 'cantidad de: centro de referencia de salud (crs) 2025', 'cantidad de: centro de regulaci√≥n m√©dica de las urgencias (samu) 2025', 'cantidad de: centro de rehabilitaci√≥n 2025', 'cantidad de: centro de salud de atenci√≥n cerrada para personas privadas de libertad 2025', 'cantidad de: centro de salud familiar (cesfam) 2025', 'cantidad de: centro de salud mental 2025', 'cantidad de: centro de salud privado 2025', 'cantidad de: centro de salud p√∫blico 2025', 'cantidad de: centro de tratamiento de adicciones (cta) 2025', 'cantidad de: cl√≠nica 2025', 'cantidad de: cl√≠nica dental 2025', 'cantidad de: cl√≠nica dental m√≥vil 2025', 'cantidad de: consultorio general rural (cgr) 2025', 'cantidad de: consultorio general urbano  (cgu) 2025', 'cantidad de: direcci√≥n servicio de salud 2025', 'cantidad de: dispositivo incorporado por crisis sanitaria 2025', 'cantidad de: estaci√≥n m√©dica rural (emr) 2025', 'cantidad de: hospital 2025', 'cantidad de: hospital de dia adulto 2025', 'cantidad de: hospital de d√≠a infanto adolescente 2025', 'cantidad de: laboratorio cl√≠nico 2025', 'cantidad de: oficina sanitaria 2025', 'cantidad de: policl√≠nico funcionarios (miner√≠a) 2025', 'cantidad de: posta de salud rural (psr) 2025', 'cantidad de: programa de reparaci√≥n y atenci√≥n integral de salud (prais) 2025', 'cantidad de: puesto de atenci√≥n m√©dica especializado (pame) incorporado por crisis sanitaria 2025', 'cantidad de: sala  externa de toma de muestras (setm) 2025', 'cantidad de: salud ambiental 2025', 'cantidad de: servicio de atenci√≥n primaria de urgencia (sapu) 2025', 'cantidad de: servicio de atenci√≥n primaria de urgencia de alta resolutividad (sar) 2025', 'cantidad de: servicio de urgencia rural (sur) 2025', 'cantidad de: unidad de atenci√≥n primaria oftalmol√≥gica (uapo) 2025', 'cantidad de: unidad de procedimientos m√≥vil 2025', 'cantidad de: unidad de salud funcionarios 2025', 'cantidad de: vacunatorio 2025', 'fecundidad 2022', 'natalidad 2022', 'mortalidad general 2022 (c/1.000 hab)', 'mortalidad infantil 2022 (c/1.000 nac.vivos)', 'matr√≠cula municipal 2024', 'matr√≠cula subvencionada 2024', 'matr√≠cula particular pagado 2024', 'matr√≠cula corporaci√≥n admin delegada 2024', 'matr√≠cula servicio local educaci√≥n 2024', 'matr√≠cula_educaci√≥n_parvularia_2024', 'matr√≠cula_ense√±anza_b√°sica_ni√±os_2024', 'matr√≠cula_educaci√≥n_b√°sica_adultos_2024', 'matr√≠cula_educaci√≥n_especial_2024', 'matr√≠cula_ense√±anza_media_human√≠stico-cient√≠fica_j√≥venes_2024', 'matr√≠cula_educaci√≥n_media_human√≠stico-cient√≠fica_adultos_2024', 'matr√≠cula_ense√±anza_media_t√©cnico_profesional_y_art√≠stica_j√≥venes_2024', 'matr√≠cula_educaci√≥n_media_t√©cnico_profesional_y_art√≠stica_adultos_2024', 'simce 4to b√°sico lectura 2022', 'simce 4to b√°sico matem√°ticas 2022', 'empresas_micro_2023', 'empresas_peque√±a_2023', 'empresas_mediana_2023', 'empresas_grande_2023', 'empresas_sin_ventas_sin_informaci√≥n_2023', 'trabajadores_micro_2023', 'trabajadores_peque√±a_2023', 'trabajadores_mediana_2023', 'trabajadores_grande_2023', 'trabajadores_sin_ventas_sin_informaci√≥n_2023', 'empresas_agricultura_ganader√≠a_2023', 'empresas_miner√≠a_2023', 'empresas_industria_manufacturera_2023', 'empresas_suministro_electricidad_2023', 'empresas_suministro_agua_2023', 'empresas_construcci√≥n_2023', 'empresas_comercio_2023', 'empresas_transporte_2023', 'empresas_alojamiento_comidas_2023', 'empresas_informaci√≥n_comunicaciones_2023', 'empresas_financieras_seguros_2023', 'empresas_inmobiliarias_2023', 'empresas_profesionales_cient√≠ficas_2023', 'empresas_servicios_administrativos_2023', 'empresas_administraci√≥n_p√∫blica_2023', 'empresas_ense√±anza_2023', 'empresas_salud_2023', 'empresas_art√≠sticas_entretenimiento_2023', 'empresas_otras_actividades_2023', 'empresas_hogares_empleadores_2023', 'empresas_organizaciones_extraterritoriales_2023', 'empresas_sin_informaci√≥n_2023', 'trabajadores_agricultura_ganader√≠a_2023', 'trabajadores_miner√≠a_2023', 'trabajadores_industria_manufacturera_2023', 'trabajadores_suministro_electricidad_2023', 'trabajadores_suministro_agua_2023', 'trabajadores_construcci√≥n_2023', 'trabajadores_comercio_2023', 'trabajadores_transporte_2023', 'trabajadores_alojamiento_comidas_2023', 'trabajadores_informaci√≥n_comunicaciones_2023', 'trabajadores_financieras_seguros_2023', 'trabajadores_inmobiliarias_2023', 'trabajadores_profesionales_cient√≠ficas_2023', 'trabajadores_servicios_administrativos_2023', 'trabajadores_administraci√≥n_p√∫blica_2023', 'trabajadores_ense√±anza_2023', 'trabajadores_salud_2023', 'trabajadores_art√≠sticas_entretenimiento_2023', 'trabajadores_otras_actividades_2023', 'trabajadores_hogares_empleadores_2023', 'trabajadores_organizaciones_extraterritoriales_2023', 'trabajadores_sin_informaci√≥n_2023', 'disponibilidad_presupuestaria_por_habitante_2023_(m$)', 'delitos mayor connotaci√≥n social 2023 (c/100.000 hab)', 'violencia intrafamiliar 2023 (c/100.000 hab)', 'n_registros', 'pct_casa', 'pct_departamento', 'pct_casa_depto', 'pct_vivienda_precaria', 'pct_paredes_solidas', 'pct_techo_solido', 'pct_piso_bueno', 'pct_agua_red_publica', 'pct_wc_bueno', 'pct_cocina_moderna', 'pct_propia_total', 'pct_arrendada', 'ingreso_promedio', 'ingreso_mediana', 'indice_calidad_materiales', 'indice_servicios_basicos', 'indice_calidad_vivienda_general', 'distancia_hospital', 'distancia_metro']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a36f1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank Feature                             Average  RF       XGB      LGBM    \n",
      "--------------------------------------------------------------------------------\n",
      "1    matr√≠cula particular pagado 2024    0.2072   0.2020   0.3888   0.0309  \n",
      "2    superficie_total                    0.1475   0.2265   0.0247   0.1914  \n",
      "3    simce 4to b√°sico lectura 2022       0.1206   0.1900   0.1588   0.0128  \n",
      "4    superficie_construida               0.0671   0.0721   0.0150   0.1144  \n",
      "5    banos                               0.0580   0.0577   0.0159   0.1004  \n",
      "6    longitud                            0.0402   0.0250   0.0046   0.0910  \n",
      "7    simce 4to b√°sico matem√°ticas 2022   0.0377   0.1101   0.0031   0.0000  \n",
      "8    distancia_metro                     0.0289   0.0135   0.0021   0.0712  \n",
      "9    latitud                             0.0284   0.0147   0.0035   0.0671  \n",
      "10   distancia_hospital                  0.0213   0.0110   0.0015   0.0513  \n",
      "11   ingreso_promedio                    0.0185   0.0153   0.0257   0.0146  \n",
      "12   dormitorios                         0.0173   0.0060   0.0021   0.0438  \n",
      "13   extranjeros 2025 (%)                0.0143   0.0016   0.0348   0.0064  \n",
      "14   pobreza multidimensional 2022 (%)   0.0113   0.0008   0.0236   0.0093  \n",
      "15   pobreza por ingresos 2022 (%)       0.0112   0.0009   0.0123   0.0204  \n",
      "16   hogares hacinados 2025 (%)          0.0098   0.0003   0.0249   0.0041  \n",
      "17   trabajadores_informaci√≥n_comunicac  0.0096   0.0031   0.0158   0.0099  \n",
      "18   trabajadores_financieras_seguros_2  0.0074   0.0007   0.0185   0.0029  \n",
      "19   matr√≠cula subvencionada 2024        0.0071   0.0017   0.0108   0.0088  \n",
      "20   empresas_otras_actividades_2023     0.0052   0.0005   0.0145   0.0006  \n",
      "  Columnas: ['precio', 'matr√≠cula particular pagado 2024', 'superficie_total', 'simce 4to b√°sico lectura 2022', 'superficie_construida', 'banos', 'longitud', 'simce 4to b√°sico matem√°ticas 2022', 'distancia_metro', 'latitud', 'distancia_hospital', 'ingreso_promedio', 'dormitorios', 'extranjeros 2025 (%)', 'pobreza multidimensional 2022 (%)', 'pobreza por ingresos 2022 (%)', 'hogares hacinados 2025 (%)', 'trabajadores_informaci√≥n_comunicaciones_2023', 'trabajadores_financieras_seguros_2023', 'matr√≠cula subvencionada 2024', 'empresas_otras_actividades_2023']\n"
     ]
    }
   ],
   "source": [
    "rf_imp = rf_pipeline.named_steps['model'].feature_importances_\n",
    "xgb_imp = xgb_pipeline.named_steps['model'].feature_importances_\n",
    "lgbm_imp = lgbm_pipeline.named_steps['model'].feature_importances_\n",
    "\n",
    "rf_norm = rf_imp / rf_imp.sum()\n",
    "xgb_norm = xgb_imp / xgb_imp.sum()\n",
    "lgbm_norm = lgbm_imp / lgbm_imp.sum()\n",
    "\n",
    "df_importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'RF': rf_norm,\n",
    "    'XGB': xgb_norm,\n",
    "    'LGBM': lgbm_norm\n",
    "})\n",
    "df_importance['Average'] = (df_importance['RF'] + df_importance['XGB'] + df_importance['LGBM']) / 3\n",
    "df_importance = df_importance.sort_values('Average', ascending=False)\n",
    "\n",
    "print(f\"{'Rank':<4} {'Feature':<35} {'Average':<8} {'RF':<8} {'XGB':<8} {'LGBM':<8}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for i, (_, row) in enumerate(df_importance.head(20).iterrows(), 1):\n",
    "    feature_name = row['feature'][:34] if len(row['feature']) > 34 else row['feature']\n",
    "    print(f\"{i:<4} {feature_name:<35} {row['Average']:<8.4f} \"\n",
    "          f\"{row['RF']:<8.4f} {row['XGB']:<8.4f} {row['LGBM']:<8.4f}\")\n",
    "    \n",
    "top_20_variables = df_importance.head(20)['feature'].tolist()\n",
    "\n",
    "df_export = X[top_20_variables].copy()\n",
    "df_export['precio'] = y\n",
    "\n",
    "df_export = df_export[['precio'] + top_20_variables]\n",
    "\n",
    "df_export.to_csv('../../data/processed/dataset_variables_finales.csv', index=False)\n",
    "\n",
    "print(f\"  Columnas: {list(df_export.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99c833d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reduced = X[top_20_variables]\n",
    "\n",
    "X_train_reduced, X_test_reduced, y_train_reduced, y_test_reduced = train_test_split(\n",
    "    X_reduced, y, test_size=0.2, random_state=42, stratify=y_binned\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "576c641a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST\n",
      "MAE: 40324559.371\n",
      "MAE_%: 17.843\n",
      "RMSE: 62650347.094\n",
      "R¬≤: 0.861\n",
      "MAPE: 21.971\n"
     ]
    }
   ],
   "source": [
    "print(\"RANDOM FOREST\")\n",
    "\n",
    "rf_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=5,\n",
    "        bootstrap=True,\n",
    "        max_samples=None,\n",
    "        max_features='sqrt',\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "rf_pipeline.fit(X_train_reduced, y_train_reduced)\n",
    "y_pred_rf = rf_pipeline.predict(X_test_reduced)\n",
    "metrics_rf = calculate_metrics(y_test_reduced, y_pred_rf)\n",
    "\n",
    "for metric, value in metrics_rf.items():\n",
    "    print(f\"{metric}: {value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1ffc210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "AN√ÅLISIS DE MAE% POR RANGOS DE PRECIO\n",
      "==================================================\n",
      "================================================================================\n",
      "AN√ÅLISIS DE MAE% POR RANGOS DE PRECIO\n",
      "================================================================================\n",
      "\n",
      "Tabla completa de resultados:\n",
      "Rango   Precio_Min   Precio_Max Precio_Promedio         MAE   MAE%  Cantidad_Casas\n",
      "   Q1  $35,000,000  $99,473,400     $80,534,531 $30,381,977 37.73%             174\n",
      "   Q2  $99,983,520 $139,969,080    $121,523,056 $25,841,131 21.26%             187\n",
      "   Q4 $193,028,635 $324,322,500    $251,217,962 $42,765,447 17.02%             180\n",
      "   Q3 $140,000,000 $190,235,520    $163,162,853 $26,705,865 16.37%             180\n",
      "   Q5 $325,692,000 $898,725,000    $511,182,584 $75,962,215 14.86%             181\n",
      "\n",
      "üî¥ RANGO CON MAYOR MAE%:\n",
      "   ‚Ä¢ Rango: Q1\n",
      "   ‚Ä¢ MAE%: 37.73%\n",
      "   ‚Ä¢ Rango de precios: $35,000,000 - $99,473,400\n",
      "   ‚Ä¢ Precio promedio: $80,534,531\n",
      "   ‚Ä¢ Cantidad de casas: 174\n",
      "\n",
      "üü¢ RANGO CON MENOR MAE%:\n",
      "   ‚Ä¢ Rango: Q5\n",
      "   ‚Ä¢ MAE%: 14.86%\n",
      "   ‚Ä¢ Rango de precios: $325,692,000 - $898,725,000\n",
      "   ‚Ä¢ Precio promedio: $511,182,584\n",
      "   ‚Ä¢ Cantidad de casas: 181\n",
      "\n",
      "--------------------------------------------------\n",
      "AN√ÅLISIS ALTERNATIVO - RANGOS DE IGUAL AMPLITUD\n",
      "--------------------------------------------------\n",
      "================================================================================\n",
      "AN√ÅLISIS DE MAE% POR RANGOS DE PRECIO\n",
      "================================================================================\n",
      "\n",
      "Tabla completa de resultados:\n",
      "  Rango   Precio_Min   Precio_Max Precio_Promedio          MAE   MAE%  Cantidad_Casas\n",
      "Rango_1  $35,000,000 $207,097,500    $125,894,026  $27,808,314 22.09%             568\n",
      "Rango_5 $726,795,000 $898,725,000    $796,371,813 $138,959,393 17.45%              21\n",
      "Rango_2 $209,934,000 $380,000,000    $281,917,124  $47,701,808 16.92%             197\n",
      "Rango_3 $382,590,000 $550,000,000    $460,928,235  $72,178,240 15.66%              77\n",
      "Rango_4 $557,208,000 $725,940,000    $630,503,893  $69,346,218 11.00%              39\n",
      "\n",
      "üî¥ RANGO CON MAYOR MAE%:\n",
      "   ‚Ä¢ Rango: Rango_1\n",
      "   ‚Ä¢ MAE%: 22.09%\n",
      "   ‚Ä¢ Rango de precios: $35,000,000 - $207,097,500\n",
      "   ‚Ä¢ Precio promedio: $125,894,026\n",
      "   ‚Ä¢ Cantidad de casas: 568\n",
      "\n",
      "üü¢ RANGO CON MENOR MAE%:\n",
      "   ‚Ä¢ Rango: Rango_4\n",
      "   ‚Ä¢ MAE%: 11.00%\n",
      "   ‚Ä¢ Rango de precios: $557,208,000 - $725,940,000\n",
      "   ‚Ä¢ Precio promedio: $630,503,893\n",
      "   ‚Ä¢ Cantidad de casas: 39\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def analyze_mae_by_price_ranges(y_true, y_pred, n_bins=5, method='quantiles'):\n",
    "    \"\"\"\n",
    "    Analiza MAE% por rangos de precio\n",
    "    \n",
    "    Parameters:\n",
    "    - y_true: valores reales\n",
    "    - y_pred: predicciones del modelo\n",
    "    - n_bins: n√∫mero de rangos a crear\n",
    "    - method: 'quantiles' (misma cantidad por rango) o 'equal_width' (rangos de igual amplitud)\n",
    "    \"\"\"\n",
    "    \n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    \n",
    "    # Crear bins seg√∫n el m√©todo elegido\n",
    "    if method == 'quantiles':\n",
    "        # Quantiles: cada rango tiene aproximadamente la misma cantidad de casas\n",
    "        bin_edges = np.quantile(y_true, np.linspace(0, 1, n_bins + 1))\n",
    "        labels = [f'Q{i+1}' for i in range(n_bins)]\n",
    "    else:  # equal_width\n",
    "        # Igual amplitud: rangos de igual tama√±o de precio\n",
    "        bin_edges = np.linspace(y_true.min(), y_true.max(), n_bins + 1)\n",
    "        labels = [f'Rango_{i+1}' for i in range(n_bins)]\n",
    "    \n",
    "    # Asignar cada casa a un bin\n",
    "    bin_indices = np.digitize(y_true, bin_edges) - 1\n",
    "    # Ajustar valores en el borde superior\n",
    "    bin_indices = np.clip(bin_indices, 0, n_bins - 1)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i in range(n_bins):\n",
    "        mask = bin_indices == i\n",
    "        \n",
    "        if np.sum(mask) == 0:\n",
    "            continue\n",
    "            \n",
    "        y_true_bin = y_true[mask]\n",
    "        y_pred_bin = y_pred[mask]\n",
    "        \n",
    "        # Calcular m√©tricas\n",
    "        mae = np.mean(np.abs(y_true_bin - y_pred_bin))\n",
    "        mae_percent = (mae / np.mean(y_true_bin)) * 100\n",
    "        rmse = np.sqrt(np.mean((y_true_bin - y_pred_bin) ** 2))\n",
    "        \n",
    "        results.append({\n",
    "            'Rango': labels[i],\n",
    "            'Precio_Min': f\"${y_true_bin.min():,.0f}\",\n",
    "            'Precio_Max': f\"${y_true_bin.max():,.0f}\",\n",
    "            'Precio_Promedio': f\"${y_true_bin.mean():,.0f}\",\n",
    "            'Precio_Promedio_Num': y_true_bin.mean(),  # Para ordenar\n",
    "            'MAE': f\"${mae:,.0f}\",\n",
    "            'MAE_Num': mae,  # Para ordenar\n",
    "            'MAE%': f\"{mae_percent:.2f}%\",\n",
    "            'MAE%_Num': mae_percent,  # Para ordenar\n",
    "            'RMSE': f\"${rmse:,.0f}\",\n",
    "            'Cantidad_Casas': int(np.sum(mask))\n",
    "        })\n",
    "    \n",
    "    df_results = pd.DataFrame(results)\n",
    "    \n",
    "    # Ordenar por MAE% descendente para ver cu√°l es peor\n",
    "    df_results = df_results.sort_values('MAE%_Num', ascending=False)\n",
    "    \n",
    "    return df_results\n",
    "\n",
    "def plot_mae_by_price_ranges(df_results):\n",
    "    \"\"\"Visualiza los resultados del an√°lisis\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # MAE% por rango (ordenado de mayor a menor)\n",
    "    x_pos = range(len(df_results))\n",
    "    axes[0,0].bar(x_pos, df_results['MAE%_Num'], color='lightcoral')\n",
    "    axes[0,0].set_title('MAE% por Rango de Precio (Mayor a Menor)', fontweight='bold')\n",
    "    axes[0,0].set_ylabel('MAE%')\n",
    "    axes[0,0].set_xticks(x_pos)\n",
    "    axes[0,0].set_xticklabels(df_results['Rango'], rotation=45)\n",
    "    \n",
    "    # Agregar valores sobre las barras\n",
    "    for i, v in enumerate(df_results['MAE%_Num']):\n",
    "        axes[0,0].text(i, v + 0.1, f'{v:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # MAE absoluto por rango\n",
    "    axes[0,1].bar(x_pos, df_results['MAE_Num'], color='lightblue')\n",
    "    axes[0,1].set_title('MAE Absoluto por Rango', fontweight='bold')\n",
    "    axes[0,1].set_ylabel('MAE ($)')\n",
    "    axes[0,1].set_xticks(x_pos)\n",
    "    axes[0,1].set_xticklabels(df_results['Rango'], rotation=45)\n",
    "    \n",
    "    # Cantidad de casas por rango\n",
    "    axes[1,0].bar(x_pos, df_results['Cantidad_Casas'], color='lightgreen')\n",
    "    axes[1,0].set_title('Cantidad de Casas por Rango', fontweight='bold')\n",
    "    axes[1,0].set_ylabel('N√∫mero de Casas')\n",
    "    axes[1,0].set_xticks(x_pos)\n",
    "    axes[1,0].set_xticklabels(df_results['Rango'], rotation=45)\n",
    "    \n",
    "    # Precio promedio por rango\n",
    "    axes[1,1].bar(x_pos, df_results['Precio_Promedio_Num'], color='gold')\n",
    "    axes[1,1].set_title('Precio Promedio por Rango', fontweight='bold')\n",
    "    axes[1,1].set_ylabel('Precio Promedio ($)')\n",
    "    axes[1,1].set_xticks(x_pos)\n",
    "    axes[1,1].set_xticklabels(df_results['Rango'], rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def print_summary(df_results):\n",
    "    \"\"\"Imprime un resumen del an√°lisis\"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"AN√ÅLISIS DE MAE% POR RANGOS DE PRECIO\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Mostrar tabla completa\n",
    "    display_cols = ['Rango', 'Precio_Min', 'Precio_Max', 'Precio_Promedio', \n",
    "                   'MAE', 'MAE%', 'Cantidad_Casas']\n",
    "    print(\"\\nTabla completa de resultados:\")\n",
    "    print(df_results[display_cols].to_string(index=False))\n",
    "    \n",
    "    # Destacar el peor rango\n",
    "    worst_range = df_results.iloc[0]\n",
    "    print(f\"\\nüî¥ RANGO CON MAYOR MAE%:\")\n",
    "    print(f\"   ‚Ä¢ Rango: {worst_range['Rango']}\")\n",
    "    print(f\"   ‚Ä¢ MAE%: {worst_range['MAE%']}\")\n",
    "    print(f\"   ‚Ä¢ Rango de precios: {worst_range['Precio_Min']} - {worst_range['Precio_Max']}\")\n",
    "    print(f\"   ‚Ä¢ Precio promedio: {worst_range['Precio_Promedio']}\")\n",
    "    print(f\"   ‚Ä¢ Cantidad de casas: {worst_range['Cantidad_Casas']}\")\n",
    "    \n",
    "    # Destacar el mejor rango\n",
    "    best_range = df_results.iloc[-1]\n",
    "    print(f\"\\nüü¢ RANGO CON MENOR MAE%:\")\n",
    "    print(f\"   ‚Ä¢ Rango: {best_range['Rango']}\")\n",
    "    print(f\"   ‚Ä¢ MAE%: {best_range['MAE%']}\")\n",
    "    print(f\"   ‚Ä¢ Rango de precios: {best_range['Precio_Min']} - {best_range['Precio_Max']}\")\n",
    "    print(f\"   ‚Ä¢ Precio promedio: {best_range['Precio_Promedio']}\")\n",
    "    print(f\"   ‚Ä¢ Cantidad de casas: {best_range['Cantidad_Casas']}\")\n",
    "\n",
    "# C√ìDIGO PARA USAR DESPU√âS DE TU MODELO:\n",
    "\n",
    "# Despu√©s de obtener tus predicciones:\n",
    "y_pred_rf = rf_pipeline.predict(X_test_reduced)\n",
    "\n",
    "# Analizar MAE% por rangos de precio\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"AN√ÅLISIS DE MAE% POR RANGOS DE PRECIO\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# An√°lisis con quantiles (recomendado - misma cantidad de casas por rango)\n",
    "results_quantiles = analyze_mae_by_price_ranges(y_test_reduced, y_pred_rf, \n",
    "                                               n_bins=5, method='quantiles')\n",
    "print_summary(results_quantiles)\n",
    "\n",
    "# Opcional: tambi√©n puedes probar con rangos de igual amplitud\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "print(\"AN√ÅLISIS ALTERNATIVO - RANGOS DE IGUAL AMPLITUD\")\n",
    "print(\"-\"*50)\n",
    "results_equal = analyze_mae_by_price_ranges(y_test_reduced, y_pred_rf, \n",
    "                                           n_bins=5, method='equal_width')\n",
    "print_summary(results_equal)\n",
    "\n",
    "# Crear visualizaciones\n",
    "plot_mae_by_price_ranges(results_quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dae579ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBOOST\n",
      "MAE: 39352941.118\n",
      "MAE_%: 17.413\n",
      "RMSE: 61293032.122\n",
      "R¬≤: 0.867\n",
      "MAPE: 20.717\n"
     ]
    }
   ],
   "source": [
    "print(\"XGBOOST\")\n",
    "\n",
    "xgb_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', xgb.XGBRegressor(\n",
    "        n_estimators=150,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=4,\n",
    "        reg_alpha=0.1,\n",
    "        reg_lambda=1.0,\n",
    "        random_state=42,\n",
    "        verbosity=0\n",
    "    ))\n",
    "])\n",
    "\n",
    "xgb_pipeline.fit(X_train_reduced, y_train_reduced)\n",
    "y_pred_xgb = xgb_pipeline.predict(X_test_reduced)\n",
    "metrics_xgb = calculate_metrics(y_test_reduced, y_pred_xgb)\n",
    "\n",
    "for metric, value in metrics_xgb.items():\n",
    "    print(f\"{metric}: {value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d536026e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIGHTGBM\n",
      "MAE: 39580166.615\n",
      "MAE_%: 17.513\n",
      "RMSE: 61819775.809\n",
      "R¬≤: 0.865\n",
      "MAPE: 20.741\n"
     ]
    }
   ],
   "source": [
    "print(\"LIGHTGBM\")\n",
    "\n",
    "lgbm_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', lgb.LGBMRegressor(\n",
    "        n_estimators=150,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=4,\n",
    "        random_state=42,\n",
    "        verbose=-1,\n",
    "        num_leaves=50,\n",
    "        min_child_samples=1\n",
    "    ))\n",
    "])\n",
    "\n",
    "lgbm_pipeline.fit(X_train_reduced, y_train_reduced)\n",
    "y_pred_lgbm = lgbm_pipeline.predict(X_test_reduced)\n",
    "metrics_lgbm = calculate_metrics(y_test_reduced, y_pred_lgbm)\n",
    "\n",
    "for metric, value in metrics_lgbm.items():\n",
    "    print(f\"{metric}: {value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03ee5f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üå≤ Optimizing RF: 100%|‚ñà| 75/75 [02:22<00:00,  1.90s/it] , Best=3739597961587760, Current=3797177986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ RESULTADOS DE LA OPTIMIZACI√ìN\n",
      "============================================================\n",
      "Mejor score: -3739597961587760.5000\n",
      "Trials completados: 75 | Trials podados: 0\n",
      "\n",
      "üîÑ Entrenando modelo final con mejores par√°metros...\n",
      "üìä COMPARACI√ìN DE M√âTRICAS\n",
      "============================================================\n",
      "      Modelo Original Modelo Optimizado   Mejora\n",
      "MAE          40324559          36190801  +10.25%\n",
      "MAE_%          17.84%            16.01%  +10.25%\n",
      "RMSE         62650347          59981062   +4.26%\n",
      "R¬≤             0.8608            0.8724   +1.35%\n",
      "MAPE           21.97%            19.31%  +12.11%\n",
      "\n",
      "üîßüìà COMPARACI√ìN DE HIPERPAR√ÅMETROS E IMPORTANCIA\n",
      "==========================================================================================\n",
      "                  Modelo Original Modelo Optimizado Importancia Porcentaje\n",
      "max_features                 sqrt              sqrt      0.5544      55.4%\n",
      "bootstrap                    True             False      0.1943      19.4%\n",
      "max_depth                      10                25      0.1006      10.1%\n",
      "min_samples_leaf                5                 1      0.0941       9.4%\n",
      "min_samples_split              10                 2      0.0306       3.1%\n",
      "n_estimators                  100               132      0.0261       2.6%\n",
      "max_samples                  None               N/A         N/A        N/A\n",
      "\n",
      "üéâ ¬°Optimizaci√≥n completada!\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import pandas as pd\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class TqdmCallback:\n",
    "    def __init__(self, n_trials):\n",
    "        self.pbar = tqdm(\n",
    "            total=n_trials, \n",
    "            desc=\"üå≤ Optimizing RF\",\n",
    "            bar_format='{desc}: {percentage:3.0f}%|{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}] {postfix}',\n",
    "            ncols=100\n",
    "        )\n",
    "        self.best_score = float('-inf')\n",
    "        \n",
    "    def __call__(self, study, trial):\n",
    "        if study.best_value > self.best_score:\n",
    "            self.best_score = study.best_value\n",
    "            \n",
    "        self.pbar.update(1)\n",
    "        self.pbar.set_postfix({\n",
    "            'Best': f'{-self.best_score:.0f}',  \n",
    "            'Current': f'{-trial.value:.0f}' if trial.value else 'Failed'\n",
    "        })\n",
    "        \n",
    "    def close(self):\n",
    "        self.pbar.close()\n",
    "\n",
    "def objective(trial):\n",
    "    bootstrap = trial.suggest_categorical('bootstrap', [True, False])\n",
    "    \n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 30),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None]),\n",
    "        'bootstrap': bootstrap,\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    if bootstrap:\n",
    "        params['max_samples'] = trial.suggest_float('max_samples', 0.7, 1.0)\n",
    "    \n",
    "    rf_pipeline_trial = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', RandomForestRegressor(**params))\n",
    "    ])\n",
    "    \n",
    "    scores = cross_val_score(\n",
    "        rf_pipeline_trial, \n",
    "        X_train_reduced, \n",
    "        y_train_reduced, \n",
    "        cv=3,  \n",
    "        scoring='neg_mean_squared_error',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    return scores.mean()\n",
    "\n",
    "def print_comparison_table(metrics_original, metrics_optimized):\n",
    "    comparison_data = {\n",
    "        'Modelo Original': [\n",
    "            f\"{metrics_original['MAE']:.0f}\",\n",
    "            f\"{metrics_original['MAE_%']:.2f}%\",\n",
    "            f\"{metrics_original['RMSE']:.0f}\",\n",
    "            f\"{metrics_original['R¬≤']:.4f}\",\n",
    "            f\"{metrics_original['MAPE']:.2f}%\"\n",
    "        ],\n",
    "        'Modelo Optimizado': [\n",
    "            f\"{metrics_optimized['MAE']:.0f}\",\n",
    "            f\"{metrics_optimized['MAE_%']:.2f}%\",\n",
    "            f\"{metrics_optimized['RMSE']:.0f}\",\n",
    "            f\"{metrics_optimized['R¬≤']:.4f}\",\n",
    "            f\"{metrics_optimized['MAPE']:.2f}%\"\n",
    "        ],\n",
    "        'Mejora': []\n",
    "    }\n",
    "    \n",
    "    # Calcular mejoras\n",
    "    for metric in ['MAE', 'MAE_%', 'RMSE', 'R¬≤', 'MAPE']:\n",
    "        if metric == 'R¬≤':\n",
    "            improvement = ((metrics_optimized[metric] - metrics_original[metric]) / abs(metrics_original[metric])) * 100\n",
    "        else:\n",
    "            improvement = ((metrics_original[metric] - metrics_optimized[metric]) / abs(metrics_original[metric])) * 100\n",
    "        comparison_data['Mejora'].append(f\"{improvement:+.2f}%\")\n",
    "    \n",
    "    df_comparison = pd.DataFrame(comparison_data, \n",
    "                                index=['MAE', 'MAE_%', 'RMSE', 'R¬≤', 'MAPE'])\n",
    "    \n",
    "    print(\"üìä COMPARACI√ìN DE M√âTRICAS\")\n",
    "    print(\"=\"*60)\n",
    "    print(df_comparison.to_string())\n",
    "\n",
    "def print_hyperparams_and_importance_table(original_params, best_params, importances):\n",
    "    all_params = set(original_params.keys()) | set(best_params.keys())\n",
    "    \n",
    "    comparison_data = {\n",
    "        'Modelo Original': [],\n",
    "        'Modelo Optimizado': [],\n",
    "        'Importancia': [],\n",
    "        'Porcentaje': []\n",
    "    }\n",
    "    \n",
    "    param_names = []\n",
    "    for param in sorted(all_params):\n",
    "        param_names.append(param)\n",
    "        original_value = original_params.get(param, 'N/A')\n",
    "        optimized_value = best_params.get(param, 'N/A')\n",
    "        \n",
    "        comparison_data['Modelo Original'].append(str(original_value))\n",
    "        comparison_data['Modelo Optimizado'].append(str(optimized_value))\n",
    "        \n",
    "        if importances and param in importances:\n",
    "            importance = importances[param]\n",
    "            comparison_data['Importancia'].append(f\"{importance:.4f}\")\n",
    "            comparison_data['Porcentaje'].append(f\"{(importance/sum(importances.values()))*100:.1f}%\")\n",
    "        else:\n",
    "            comparison_data['Importancia'].append('N/A')\n",
    "            comparison_data['Porcentaje'].append('N/A')\n",
    "    \n",
    "    df_combined = pd.DataFrame(comparison_data, index=param_names)\n",
    "    \n",
    "    if importances:\n",
    "        df_combined['sort_key'] = df_combined['Importancia'].apply(\n",
    "            lambda x: float(x) if x != 'N/A' else 0\n",
    "        )\n",
    "        df_combined = df_combined.sort_values('sort_key', ascending=False).drop('sort_key', axis=1)\n",
    "    \n",
    "    print(\"\\nüîßüìà COMPARACI√ìN DE HIPERPAR√ÅMETROS E IMPORTANCIA\")\n",
    "    print(\"=\"*90)\n",
    "    print(df_combined.to_string())\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction='maximize', \n",
    "    sampler=optuna.samplers.TPESampler(seed=42),\n",
    "    pruner=optuna.pruners.MedianPruner(n_startup_trials=10, n_warmup_steps=3)\n",
    ")\n",
    "\n",
    "n_trials = 75  \n",
    "\n",
    "callback = TqdmCallback(n_trials)\n",
    "\n",
    "try:\n",
    "    study.optimize(objective, n_trials=n_trials, callbacks=[callback], show_progress_bar=False)\n",
    "finally:\n",
    "    callback.close()\n",
    "\n",
    "print(\"\\nüéØ RESULTADOS DE LA OPTIMIZACI√ìN\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Mejor score: {study.best_value:.4f}\")\n",
    "print(f\"Trials completados: {len(study.trials)} | Trials podados: {len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED])}\")\n",
    "\n",
    "print(\"\\nüîÑ Entrenando modelo final con mejores par√°metros...\")\n",
    "\n",
    "best_rf_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', RandomForestRegressor(**study.best_params, random_state=42))\n",
    "])\n",
    "\n",
    "best_rf_pipeline.fit(X_train_reduced, y_train_reduced)\n",
    "\n",
    "y_pred_rf_optimized = best_rf_pipeline.predict(X_test_reduced)\n",
    "\n",
    "metrics_rf_optimized = calculate_metrics(y_test_reduced, y_pred_rf_optimized)\n",
    "\n",
    "original_params = {\n",
    "    'bootstrap': True,  \n",
    "    'max_depth': 10,          \n",
    "    'max_features': 'sqrt',\n",
    "    'min_samples_leaf': 5,     \n",
    "    'min_samples_split': 10,  \n",
    "    'n_estimators': 100,\n",
    "    'max_samples': None        \n",
    "}\n",
    "\n",
    "print_comparison_table(metrics_rf, metrics_rf_optimized)\n",
    "\n",
    "try:\n",
    "    importances = optuna.importance.get_param_importances(study)\n",
    "except:\n",
    "    importances = {}\n",
    "\n",
    "print_hyperparams_and_importance_table(original_params, study.best_params, importances)\n",
    "\n",
    "print(\"\\nüéâ ¬°Optimizaci√≥n completada!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9cb8bfcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üöÄ Optimizing XGB:   0%|                                                   | 0/100 [00:00<?, ?it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üöÄ Optimizing XGB: 100%|‚ñà| 100/100 [01:15<00:00,  1.32it/s] , Best=3627212893030160, Current=3664224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ RESULTADOS DE LA OPTIMIZACI√ìN - XGBOOST\n",
      "============================================================\n",
      "Mejor score: -3627212893030160.0000\n",
      "Trials completados: 100 | Trials podados: 0\n",
      "üìä COMPARACI√ìN DE M√âTRICAS - XGBOOST\n",
      "============================================================\n",
      "      Modelo Original Modelo Optimizado  Mejora\n",
      "MAE          39352941          36785669  +6.52%\n",
      "MAE_%          17.41%            16.28%  +6.52%\n",
      "RMSE         61293032          59901050  +2.27%\n",
      "R¬≤             0.8668            0.8728  +0.69%\n",
      "MAPE           20.72%            19.41%  +6.30%\n",
      "\n",
      "üîßüìà COMPARACI√ìN DE HIPERPAR√ÅMETROS E IMPORTANCIA - XGBOOST\n",
      "==========================================================================================\n",
      "                  Modelo Original     Modelo Optimizado Importancia Porcentaje\n",
      "learning_rate                0.05  0.044591445066116224      0.5944      59.4%\n",
      "max_depth                       4                     9      0.2025      20.3%\n",
      "n_estimators                  150                   168      0.0898       9.0%\n",
      "gamma                         0.0    2.9946053002432924      0.0349       3.5%\n",
      "colsample_bytree              1.0    0.7274723740462301      0.0217       2.2%\n",
      "subsample                     1.0    0.6512778177321682      0.0198       2.0%\n",
      "min_child_weight                1                     2      0.0155       1.6%\n",
      "colsample_bylevel             1.0    0.8142433273749217      0.0099       1.0%\n",
      "reg_alpha                     0.1     6.073088326643914      0.0058       0.6%\n",
      "reg_lambda                    1.0     2.587598816533618      0.0056       0.6%\n",
      "\n",
      "üéâ ¬°Optimizaci√≥n XGBoost completada!\n"
     ]
    }
   ],
   "source": [
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class TqdmCallback:\n",
    "    def __init__(self, n_trials):\n",
    "        self.pbar = tqdm(\n",
    "            total=n_trials, \n",
    "            desc=\"üöÄ Optimizing XGB\",\n",
    "            bar_format='{desc}: {percentage:3.0f}%|{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}] {postfix}',\n",
    "            ncols=100\n",
    "        )\n",
    "        self.best_score = float('-inf')\n",
    "        \n",
    "    def __call__(self, study, trial):\n",
    "        if study.best_value > self.best_score:\n",
    "            self.best_score = study.best_value\n",
    "            \n",
    "        self.pbar.update(1)\n",
    "        self.pbar.set_postfix({\n",
    "            'Best': f'{-self.best_score:.0f}',  \n",
    "            'Current': f'{-trial.value:.0f}' if trial.value else 'Failed'\n",
    "        })\n",
    "        \n",
    "    def close(self):\n",
    "        self.pbar.close()\n",
    "\n",
    "def objective_xgb(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.6, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 10.0),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 10.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0.0, 5.0),\n",
    "        'random_state': 42,\n",
    "        'verbosity': 0,\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "    \n",
    "    xgb_pipeline_trial = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', xgb.XGBRegressor(**params))\n",
    "    ])\n",
    "    \n",
    "    scores = cross_val_score(\n",
    "        xgb_pipeline_trial, \n",
    "        X_train_reduced, \n",
    "        y_train_reduced, \n",
    "        cv=3,  \n",
    "        scoring='neg_mean_squared_error',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    return scores.mean()\n",
    "\n",
    "def print_comparison_table_xgb(metrics_original, metrics_optimized):\n",
    "    comparison_data = {\n",
    "        'Modelo Original': [\n",
    "            f\"{metrics_original['MAE']:.0f}\",\n",
    "            f\"{metrics_original['MAE_%']:.2f}%\",\n",
    "            f\"{metrics_original['RMSE']:.0f}\",\n",
    "            f\"{metrics_original['R¬≤']:.4f}\",\n",
    "            f\"{metrics_original['MAPE']:.2f}%\"\n",
    "        ],\n",
    "        'Modelo Optimizado': [\n",
    "            f\"{metrics_optimized['MAE']:.0f}\",\n",
    "            f\"{metrics_optimized['MAE_%']:.2f}%\",\n",
    "            f\"{metrics_optimized['RMSE']:.0f}\",\n",
    "            f\"{metrics_optimized['R¬≤']:.4f}\",\n",
    "            f\"{metrics_optimized['MAPE']:.2f}%\"\n",
    "        ],\n",
    "        'Mejora': []\n",
    "    }\n",
    "\n",
    "    for metric in ['MAE', 'MAE_%', 'RMSE', 'R¬≤', 'MAPE']:\n",
    "        if metric == 'R¬≤':\n",
    "            improvement = ((metrics_optimized[metric] - metrics_original[metric]) / abs(metrics_original[metric])) * 100\n",
    "        else:\n",
    "            improvement = ((metrics_original[metric] - metrics_optimized[metric]) / abs(metrics_original[metric])) * 100\n",
    "        comparison_data['Mejora'].append(f\"{improvement:+.2f}%\")\n",
    "    \n",
    "    df_comparison = pd.DataFrame(comparison_data, \n",
    "                                index=['MAE', 'MAE_%', 'RMSE', 'R¬≤', 'MAPE'])\n",
    "    \n",
    "    print(\"üìä COMPARACI√ìN DE M√âTRICAS - XGBOOST\")\n",
    "    print(\"=\"*60)\n",
    "    print(df_comparison.to_string())\n",
    "\n",
    "def print_hyperparams_and_importance_table_xgb(original_params, best_params, importances):\n",
    "    all_params = set(original_params.keys()) | set(best_params.keys())\n",
    "    \n",
    "    comparison_data = {\n",
    "        'Modelo Original': [],\n",
    "        'Modelo Optimizado': [],\n",
    "        'Importancia': [],\n",
    "        'Porcentaje': []\n",
    "    }\n",
    "    \n",
    "    param_names = []\n",
    "    for param in sorted(all_params):\n",
    "        param_names.append(param)\n",
    "        original_value = original_params.get(param, 'N/A')\n",
    "        optimized_value = best_params.get(param, 'N/A')\n",
    "        \n",
    "        comparison_data['Modelo Original'].append(str(original_value))\n",
    "        comparison_data['Modelo Optimizado'].append(str(optimized_value))\n",
    "        \n",
    "        if importances and param in importances:\n",
    "            importance = importances[param]\n",
    "            comparison_data['Importancia'].append(f\"{importance:.4f}\")\n",
    "            comparison_data['Porcentaje'].append(f\"{(importance/sum(importances.values()))*100:.1f}%\")\n",
    "        else:\n",
    "            comparison_data['Importancia'].append('N/A')\n",
    "            comparison_data['Porcentaje'].append('N/A')\n",
    "    \n",
    "    df_combined = pd.DataFrame(comparison_data, index=param_names)\n",
    "    \n",
    "    if importances:\n",
    "        df_combined['sort_key'] = df_combined['Importancia'].apply(\n",
    "            lambda x: float(x) if x != 'N/A' else 0\n",
    "        )\n",
    "        df_combined = df_combined.sort_values('sort_key', ascending=False).drop('sort_key', axis=1)\n",
    "    \n",
    "    print(\"\\nüîßüìà COMPARACI√ìN DE HIPERPAR√ÅMETROS E IMPORTANCIA - XGBOOST\")\n",
    "    print(\"=\"*90)\n",
    "    print(df_combined.to_string())\n",
    "\n",
    "study_xgb = optuna.create_study(\n",
    "    direction='maximize', \n",
    "    sampler=optuna.samplers.TPESampler(seed=42),\n",
    "    pruner=optuna.pruners.MedianPruner(n_startup_trials=15, n_warmup_steps=5)\n",
    ")\n",
    "\n",
    "n_trials = 100  \n",
    "\n",
    "callback = TqdmCallback(n_trials)\n",
    "\n",
    "try:\n",
    "    study_xgb.optimize(objective_xgb, n_trials=n_trials, callbacks=[callback], show_progress_bar=False)\n",
    "finally:\n",
    "    callback.close()\n",
    "\n",
    "print(\"\\nüéØ RESULTADOS DE LA OPTIMIZACI√ìN - XGBOOST\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Mejor score: {study_xgb.best_value:.4f}\")\n",
    "print(f\"Trials completados: {len(study_xgb.trials)} | Trials podados: {len([t for t in study_xgb.trials if t.state == optuna.trial.TrialState.PRUNED])}\")\n",
    "\n",
    "best_xgb_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', xgb.XGBRegressor(**study_xgb.best_params, random_state=42, verbosity=0))\n",
    "])\n",
    "\n",
    "best_xgb_pipeline.fit(X_train_reduced, y_train_reduced)\n",
    "\n",
    "y_pred_xgb_optimized = best_xgb_pipeline.predict(X_test_reduced)\n",
    "\n",
    "metrics_xgb_optimized = calculate_metrics(y_test_reduced, y_pred_xgb_optimized)\n",
    "\n",
    "original_params_xgb = {\n",
    "    'n_estimators': 150,\n",
    "    'learning_rate': 0.05,\n",
    "    'max_depth': 4,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 1.0,\n",
    "    'min_child_weight': 1,      \n",
    "    'subsample': 1.0,            \n",
    "    'colsample_bytree': 1.0,     \n",
    "    'colsample_bylevel': 1.0,   \n",
    "    'gamma': 0.0                \n",
    "}\n",
    "\n",
    "print_comparison_table_xgb(metrics_xgb, metrics_xgb_optimized)\n",
    "\n",
    "try:\n",
    "    importances_xgb = optuna.importance.get_param_importances(study_xgb)\n",
    "except:\n",
    "    importances_xgb = {}\n",
    "\n",
    "print_hyperparams_and_importance_table_xgb(original_params_xgb, study_xgb.best_params, importances_xgb)\n",
    "\n",
    "print(\"\\nüéâ ¬°Optimizaci√≥n XGBoost completada!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c8605cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üí° Optimizing LGBM: 100%|‚ñà| 100/100 [01:14<00:00,  1.35it/s] , Best=3698246205498024, Current=377196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ RESULTADOS DE LA OPTIMIZACI√ìN - LIGHTGBM\n",
      "============================================================\n",
      "Mejor score: -3698246205498024.0000\n",
      "Trials completados: 100 | Trials podados: 0\n",
      "üìä COMPARACI√ìN DE M√âTRICAS - LIGHTGBM\n",
      "============================================================\n",
      "      Modelo Original Modelo Optimizado  Mejora\n",
      "MAE          39580167          37903421  +4.24%\n",
      "MAE_%          17.51%            16.77%  +4.24%\n",
      "RMSE         61819776          60647684  +1.90%\n",
      "R¬≤             0.8645            0.8696  +0.59%\n",
      "MAPE           20.74%            19.82%  +4.42%\n",
      "\n",
      "üîßüìà COMPARACI√ìN DE HIPERPAR√ÅMETROS E IMPORTANCIA - LIGHTGBM\n",
      "==========================================================================================\n",
      "                  Modelo Original    Modelo Optimizado Importancia Porcentaje\n",
      "learning_rate                0.05  0.10649141961617677      0.6211      62.1%\n",
      "reg_lambda                    0.0    9.268750872920542      0.1276      12.8%\n",
      "reg_alpha                     0.0   0.6957294406281602      0.0611       6.1%\n",
      "min_split_gain                0.0   0.9374056774119248      0.0555       5.5%\n",
      "min_child_samples               1                    5      0.0411       4.1%\n",
      "n_estimators                  150                  184      0.0353       3.5%\n",
      "subsample                     1.0   0.9188458556829474      0.0195       2.0%\n",
      "min_child_weight            0.001   1.3553491787322969      0.0194       1.9%\n",
      "num_leaves                     50                  223      0.0095       1.0%\n",
      "max_depth                       4                    6      0.0036       0.4%\n",
      "colsample_bytree              1.0   0.5813275113023741      0.0033       0.3%\n",
      "subsample_freq                  0                    5      0.0031       0.3%\n",
      "\n",
      "üéâ ¬°Optimizaci√≥n LightGBM completada!\n"
     ]
    }
   ],
   "source": [
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class TqdmCallback:\n",
    "    def __init__(self, n_trials):\n",
    "        self.pbar = tqdm(\n",
    "            total=n_trials, \n",
    "            desc=\"üí° Optimizing LGBM\",\n",
    "            bar_format='{desc}: {percentage:3.0f}%|{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}] {postfix}',\n",
    "            ncols=100\n",
    "        )\n",
    "        self.best_score = float('-inf')\n",
    "        \n",
    "    def __call__(self, study, trial):\n",
    "        if study.best_value > self.best_score:\n",
    "            self.best_score = study.best_value\n",
    "            \n",
    "        self.pbar.update(1)\n",
    "        self.pbar.set_postfix({\n",
    "            'Best': f'{-self.best_score:.0f}',  \n",
    "            'Current': f'{-trial.value:.0f}' if trial.value else 'Failed'\n",
    "        })\n",
    "        \n",
    "    def close(self):\n",
    "        self.pbar.close()\n",
    "\n",
    "def objective_lgbm(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', -1, 15),  \n",
    "        'num_leaves': trial.suggest_int('num_leaves', 15, 300),  \n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 50), \n",
    "        'min_child_weight': trial.suggest_float('min_child_weight', 1e-3, 10.0, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'subsample_freq': trial.suggest_int('subsample_freq', 0, 10),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 10.0),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 10.0),\n",
    "        'min_split_gain': trial.suggest_float('min_split_gain', 0.0, 1.0),\n",
    "        'random_state': 42,\n",
    "        'verbose': -1,\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "    \n",
    "    if params['max_depth'] != -1:\n",
    "        max_leaves = 2 ** params['max_depth']\n",
    "        if params['num_leaves'] >= max_leaves:\n",
    "            params['num_leaves'] = max(15, max_leaves - 1)  \n",
    "    \n",
    "    params['num_leaves'] = max(15, params['num_leaves'])\n",
    "    \n",
    "    try:\n",
    "        lgbm_pipeline_trial = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('model', lgb.LGBMRegressor(**params))\n",
    "        ])\n",
    "        \n",
    "        scores = cross_val_score(\n",
    "            lgbm_pipeline_trial, \n",
    "            X_train_reduced, \n",
    "            y_train_reduced, \n",
    "            cv=3,  \n",
    "            scoring='neg_mean_squared_error',\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        return scores.mean()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error en trial: {e}\")\n",
    "        return float('-inf')\n",
    "\n",
    "def print_comparison_table_lgbm(metrics_original, metrics_optimized):\n",
    "    comparison_data = {\n",
    "        'Modelo Original': [\n",
    "            f\"{metrics_original['MAE']:.0f}\",\n",
    "            f\"{metrics_original['MAE_%']:.2f}%\",\n",
    "            f\"{metrics_original['RMSE']:.0f}\",\n",
    "            f\"{metrics_original['R¬≤']:.4f}\",\n",
    "            f\"{metrics_original['MAPE']:.2f}%\"\n",
    "        ],\n",
    "        'Modelo Optimizado': [\n",
    "            f\"{metrics_optimized['MAE']:.0f}\",\n",
    "            f\"{metrics_optimized['MAE_%']:.2f}%\",\n",
    "            f\"{metrics_optimized['RMSE']:.0f}\",\n",
    "            f\"{metrics_optimized['R¬≤']:.4f}\",\n",
    "            f\"{metrics_optimized['MAPE']:.2f}%\"\n",
    "        ],\n",
    "        'Mejora': []\n",
    "    }\n",
    "    \n",
    "    for metric in ['MAE', 'MAE_%', 'RMSE', 'R¬≤', 'MAPE']:\n",
    "        if metric == 'R¬≤':\n",
    "            improvement = ((metrics_optimized[metric] - metrics_original[metric]) / abs(metrics_original[metric])) * 100\n",
    "        else:\n",
    "            improvement = ((metrics_original[metric] - metrics_optimized[metric]) / abs(metrics_original[metric])) * 100\n",
    "        comparison_data['Mejora'].append(f\"{improvement:+.2f}%\")\n",
    "    \n",
    "    df_comparison = pd.DataFrame(comparison_data, \n",
    "                                index=['MAE', 'MAE_%', 'RMSE', 'R¬≤', 'MAPE'])\n",
    "    \n",
    "    print(\"üìä COMPARACI√ìN DE M√âTRICAS - LIGHTGBM\")\n",
    "    print(\"=\"*60)\n",
    "    print(df_comparison.to_string())\n",
    "\n",
    "def print_hyperparams_and_importance_table_lgbm(original_params, best_params, importances):\n",
    "    all_params = set(original_params.keys()) | set(best_params.keys())\n",
    "    \n",
    "    comparison_data = {\n",
    "        'Modelo Original': [],\n",
    "        'Modelo Optimizado': [],\n",
    "        'Importancia': [],\n",
    "        'Porcentaje': []\n",
    "    }\n",
    "    \n",
    "    param_names = []\n",
    "    for param in sorted(all_params):\n",
    "        param_names.append(param)\n",
    "        original_value = original_params.get(param, 'N/A')\n",
    "        optimized_value = best_params.get(param, 'N/A')\n",
    "        \n",
    "        comparison_data['Modelo Original'].append(str(original_value))\n",
    "        comparison_data['Modelo Optimizado'].append(str(optimized_value))\n",
    "        \n",
    "        if importances and param in importances:\n",
    "            importance = importances[param]\n",
    "            comparison_data['Importancia'].append(f\"{importance:.4f}\")\n",
    "            comparison_data['Porcentaje'].append(f\"{(importance/sum(importances.values()))*100:.1f}%\")\n",
    "        else:\n",
    "            comparison_data['Importancia'].append('N/A')\n",
    "            comparison_data['Porcentaje'].append('N/A')\n",
    "    \n",
    "    df_combined = pd.DataFrame(comparison_data, index=param_names)\n",
    "    \n",
    "    if importances:\n",
    "        df_combined['sort_key'] = df_combined['Importancia'].apply(\n",
    "            lambda x: float(x) if x != 'N/A' else 0\n",
    "        )\n",
    "        df_combined = df_combined.sort_values('sort_key', ascending=False).drop('sort_key', axis=1)\n",
    "    \n",
    "    print(\"\\nüîßüìà COMPARACI√ìN DE HIPERPAR√ÅMETROS E IMPORTANCIA - LIGHTGBM\")\n",
    "    print(\"=\"*90)\n",
    "    print(df_combined.to_string())\n",
    "\n",
    "study_lgbm = optuna.create_study(\n",
    "    direction='maximize', \n",
    "    sampler=optuna.samplers.TPESampler(seed=42),\n",
    "    pruner=optuna.pruners.MedianPruner(n_startup_trials=15, n_warmup_steps=5)\n",
    ")\n",
    "\n",
    "n_trials = 100  \n",
    "\n",
    "callback = TqdmCallback(n_trials)\n",
    "\n",
    "try:\n",
    "    study_lgbm.optimize(objective_lgbm, n_trials=n_trials, callbacks=[callback], show_progress_bar=False)\n",
    "finally:\n",
    "    callback.close()\n",
    "\n",
    "print(\"\\nüéØ RESULTADOS DE LA OPTIMIZACI√ìN - LIGHTGBM\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Mejor score: {study_lgbm.best_value:.4f}\")\n",
    "print(f\"Trials completados: {len(study_lgbm.trials)} | Trials podados: {len([t for t in study_lgbm.trials if t.state == optuna.trial.TrialState.PRUNED])}\")\n",
    "\n",
    "best_lgbm_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', lgb.LGBMRegressor(**study_lgbm.best_params, random_state=42, verbose=-1))\n",
    "])\n",
    "\n",
    "best_lgbm_pipeline.fit(X_train_reduced, y_train_reduced)\n",
    "\n",
    "y_pred_lgbm_optimized = best_lgbm_pipeline.predict(X_test_reduced)\n",
    "\n",
    "metrics_lgbm_optimized = calculate_metrics(y_test_reduced, y_pred_lgbm_optimized)\n",
    "\n",
    "original_params_lgbm = {\n",
    "    'n_estimators': 150,\n",
    "    'learning_rate': 0.05,\n",
    "    'max_depth': 4,\n",
    "    'num_leaves': 50,\n",
    "    'min_child_samples': 1,\n",
    "    'min_child_weight': 1e-3,  \n",
    "    'subsample': 1.0,             \n",
    "    'subsample_freq': 0,         \n",
    "    'colsample_bytree': 1.0,     \n",
    "    'reg_alpha': 0.0,            \n",
    "    'reg_lambda': 0.0,            \n",
    "    'min_split_gain': 0.0       \n",
    "}\n",
    "\n",
    "print_comparison_table_lgbm(metrics_lgbm, metrics_lgbm_optimized)\n",
    "\n",
    "try:\n",
    "    importances_lgbm = optuna.importance.get_param_importances(study_lgbm)\n",
    "except:\n",
    "    importances_lgbm = {}\n",
    "\n",
    "print_hyperparams_and_importance_table_lgbm(original_params_lgbm, study_lgbm.best_params, importances_lgbm)\n",
    "\n",
    "print(\"\\nüéâ ¬°Optimizaci√≥n LightGBM completada!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsprojects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
